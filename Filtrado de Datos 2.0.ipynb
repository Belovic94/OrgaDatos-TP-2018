{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from datetime import datetime\n",
    "\n",
    "events = pd.read_csv('events_up_to_01062018.csv', low_memory = False)\n",
    "training = pd.read_csv('labels_training_set.csv', low_memory = False)\n",
    "kaggle = pd.read_csv('trocafone_kaggle_test.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithLabel = events.merge(training, how='left', left_on='person', right_on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithLabel['timestamp'] = pd.to_datetime(eventsWithLabel['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccWeek = {0: \"Monday\",\n",
    "            1: \"Tuesday\",\n",
    "            2: \"Wednesday\",\n",
    "            3: \"Thursday\",\n",
    "            4: \"Friday\",\n",
    "            5: \"Saturday\",\n",
    "            6: \"Sunday\"}\n",
    "\n",
    "diccMonth = {1: \"January\",\n",
    "             2: \"Febrary\",\n",
    "             3: \"March\",\n",
    "             4: \"April\",\n",
    "             5: \"May\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtengo los dias de la semana\n",
    "eventsWithLabel['dayweek'] = eventsWithLabel.timestamp.dt.dayofweek\n",
    "eventsWithLabel[\"dayweek\"] = eventsWithLabel[\"dayweek\"].map(lambda x: diccWeek.get(x))\n",
    "#Obtengo la fecha\n",
    "eventsWithLabel['fecha'] = eventsWithLabel.timestamp.dt.date\n",
    "#Separo la marca\n",
    "eventsWithLabel['marca'] = eventsWithLabel['model'].map(lambda x: str(x).split()[0])\n",
    "#Separo los dias del mes\n",
    "eventsWithLabel['month'] = eventsWithLabel.timestamp.dt.month\n",
    "eventsWithLabel[\"month\"] = eventsWithLabel[\"month\"].map(lambda x: diccMonth.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupbyCantEventos = eventsWithLabel.groupby('person', as_index = False)['event'].agg({'cantEventos': 'count'})\n",
    "groupbyCantEventos.sort_values(by = 'cantEventos', ascending = False)\n",
    "eventsWithLabel = pd.merge(eventsWithLabel, groupbyCantEventos, on = 'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro a la gente que no tiene el evento visited_site\n",
    "personasConVisitas = eventsWithLabel.loc[eventsWithLabel['event'] == 'visited site']\\\n",
    "                             .drop_duplicates(subset = 'person', keep = 'first')['person'].tolist()\n",
    "dataNotVisit = eventsWithLabel.loc[eventsWithLabel['person'].isin(personasConVisitas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithLabel2 = dataNotVisit.loc[dataNotVisit['event'] == 'visited site'].groupby(['person', 'fecha'], as_index = False).agg({'city': 'first', 'region': 'first', 'country': 'first', 'device_type': 'first', 'operating_system_version': 'first', 'channel': 'first', 'new_vs_returning': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithLabel3 = pd.merge(dataNotVisit, eventsWithLabel2, on = ['person', 'fecha'])\n",
    "eventsWithLabel3.drop(['region_x', 'device_type_x', 'operating_system_version_x', 'country_x', 'city_x', 'channel_x', 'new_vs_returning_x'], axis = 1, inplace = True)\n",
    "eventsWithLabel3.rename(columns = {'region_y': 'region', 'device_type_y': 'device_type', 'operating_system_version_y': 'SO', 'city_y': 'city', 'country_y': 'country', 'channel_y': 'channel', 'new_vs_returning_y': 'new_vs_returning'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithLabel3[\"color\"] = eventsWithLabel3.color.str.split(\" \", expand=True)\n",
    "eventsWithLabel3[\"SO\"] = eventsWithLabel3.SO.str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = eventsWithLabel3.loc[eventsWithLabel3[\"label\"].notnull()]\n",
    "test = eventsWithLabel3.loc[eventsWithLabel3[\"label\"].isnull()] \n",
    "test = test.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.merge(kaggle, test, how =\"left\", on = \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle2.loc[kaggle2[\"campaign_source\"].notnull()].groupby(\"person\")[\"campaign_source\"].first().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataVisitasTrain = train.groupby([\"person\", \"fecha\"], as_index =False)[\"timestamp\"].count()\n",
    "dataVisitasKaggle = kaggle.groupby([\"person\", \"fecha\"], as_index =False)[\"timestamp\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataVisitasPromTrain = dataVisitasTrain.groupby([\"person\"], as_index=False)[\"timestamp\"].agg({\"visitasProm\": \"mean\"})\n",
    "dataVisitasPromKaggle = dataVisitasKaggle.groupby([\"person\"], as_index=False)[\"timestamp\"].agg({\"visitasProm\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, dataVisitasPromTrain, how = \"left\", on= \"person\")\n",
    "kaggle = pd.merge(kaggle, dataVisitasPromKaggle, how = \"left\", on= \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determino si el usuario es new or returning.\n",
    "dataNewReturningTrain = train.groupby([\"person\", \"new_vs_returning\"])[\"timestamp\"].count().unstack()\n",
    "dataNewReturningTrain = dataNewReturningTrain.fillna(0)\n",
    "dataNewReturningTrain[\"returning\"] = dataNewReturningTrain[\"Returning\"].map(lambda x: 1 if x > 0 else 0)\n",
    "dataNewReturningTrain = dataNewReturningTrain.reset_index().drop([\"New\",\"Returning\"], axis = 1)\n",
    "train = train.drop(['new_vs_returning'], axis = 1)\n",
    "train = pd.merge(train, dataNewReturningTrain, how = 'left', on = 'person')\n",
    "\n",
    "dataNewReturningKaggle = kaggle.groupby([\"person\", \"new_vs_returning\"])[\"timestamp\"].count().unstack()\n",
    "dataNewReturningKaggle = dataNewReturningKaggle.fillna(0)\n",
    "dataNewReturningKaggle[\"returning\"] = dataNewReturningKaggle[\"Returning\"].map(lambda x: 1 if x > 0 else 0)\n",
    "dataNewReturningKaggle = dataNewReturningKaggle.reset_index().drop([\"New\",\"Returning\"], axis = 1)\n",
    "kaggle = kaggle.drop(['new_vs_returning'], axis = 1)\n",
    "kaggle = pd.merge(kaggle, dataNewReturningKaggle, how = 'left', on = 'person')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPastConversionsTrain = train.loc[train[\"event\"] == \"conversion\"].groupby(\"person\", as_index = False)[\"timestamp\"].agg({\"pastConversions\":\"count\"})\n",
    "dataPastConversionsKaggle = kaggle.loc[kaggle[\"event\"] == \"conversion\"].groupby(\"person\", as_index = False)[\"timestamp\"].agg({\"pastConversions\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, dataPastConversionsTrain, how = 'left', on = 'person')\n",
    "train[\"pastConversions\"] = train[\"pastConversions\"].fillna(0)\n",
    "kaggle = pd.merge(kaggle, dataPastConversionsKaggle, how = 'left', on = 'person')\n",
    "kaggle[\"pastConversions\"] = kaggle[\"pastConversions\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPersonRegion = train.groupby(\"person\")[[\"region\", \"label\", \"timestamp\"]].agg(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataRegiones = dataPersonRegion.groupby([\"region\", \"label\"]).count()\n",
    "# dataRegionesFilter = dataPersonRegion.groupby([\"region\", \"label\" ])[\"timestamp\"].count().unstack().fillna(value = 0)\n",
    "\n",
    "dataRegionesFilter = dataRegiones.loc[dataRegiones[\"timestamp\"] > 10]\n",
    "dataRegionesFilter = dataRegionesFilter[\"timestamp\"].unstack().fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRegionesFilter[\"ratioCompra\"] = dataRegionesFilter[1.0]/dataRegionesFilter[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>ratioCompra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Santa Catarina</th>\n",
       "      <td>334.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.077844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maranhao</th>\n",
       "      <td>317.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.075710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Para</th>\n",
       "      <td>291.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.075601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rio Grande do Sul</th>\n",
       "      <td>539.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.066790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minas Gerais</th>\n",
       "      <td>1487.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.059180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parana</th>\n",
       "      <td>558.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.059140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Federal District</th>\n",
       "      <td>342.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.058480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sao Paulo</th>\n",
       "      <td>5090.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.056582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>3099.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.054211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Espirito Santo</th>\n",
       "      <td>319.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.053292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rio de Janeiro</th>\n",
       "      <td>1506.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.051793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahia</th>\n",
       "      <td>1144.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.050699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goias</th>\n",
       "      <td>364.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.046703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pernambuco</th>\n",
       "      <td>583.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.046312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ceara</th>\n",
       "      <td>548.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rondonia</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piaui</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sergipe</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tocantins</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rio Grande do Norte</th>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acre</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paraíba</th>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alagoas</th>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mato Grosso do Sul</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mato Grosso</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buenos Aires F.D.</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazonas</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amapa</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                   0.0    1.0  ratioCompra\n",
       "region                                         \n",
       "Santa Catarina        334.0   26.0     0.077844\n",
       "Maranhao              317.0   24.0     0.075710\n",
       "Para                  291.0   22.0     0.075601\n",
       "Rio Grande do Sul     539.0   36.0     0.066790\n",
       "Minas Gerais         1487.0   88.0     0.059180\n",
       "Parana                558.0   33.0     0.059140\n",
       "Federal District      342.0   20.0     0.058480\n",
       "Sao Paulo            5090.0  288.0     0.056582\n",
       "Unknown              3099.0  168.0     0.054211\n",
       "Espirito Santo        319.0   17.0     0.053292\n",
       "Rio de Janeiro       1506.0   78.0     0.051793\n",
       "Bahia                1144.0   58.0     0.050699\n",
       "Goias                 364.0   17.0     0.046703\n",
       "Pernambuco            583.0   27.0     0.046312\n",
       "Ceara                 548.0   12.0     0.021898\n",
       "Rondonia               63.0    0.0     0.000000\n",
       "Piaui                 157.0    0.0     0.000000\n",
       "Sergipe               100.0    0.0     0.000000\n",
       "Tocantins              88.0    0.0     0.000000\n",
       "Rio Grande do Norte   242.0    0.0     0.000000\n",
       "Acre                   26.0    0.0     0.000000\n",
       "Paraíba               177.0    0.0     0.000000\n",
       "Alagoas               173.0    0.0     0.000000\n",
       "Mato Grosso do Sul    123.0    0.0     0.000000\n",
       "Mato Grosso           102.0    0.0     0.000000\n",
       "California             55.0    0.0     0.000000\n",
       "Buenos Aires F.D.      12.0    0.0     0.000000\n",
       "Amazonas              151.0    0.0     0.000000\n",
       "Amapa                  37.0    0.0     0.000000\n",
       "New York               41.0    0.0     0.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRegionesFilter.sort_values(by = \"ratioCompra\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionesMasCompras = [\"Santa Catarina\", \"Maranhao\", \"Para\", \"Rio Grande do Sul\", \"Minas Gerais\", \"Parana\", \"Federal District\", \"Sao Paulo\", \"Espirito Santo\", \"Rio de Janeiro\", \"Bahia\", \"Goias\", \"Pernambuco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"url\", \"sku\", \"skus\", \"search_term\", \"staticpage\", \"campaign_source\", \"search_engine\", \"screen_resolution\", \"browser_version\"], axis = 1)\n",
    "kaggle = kaggle.drop([\"url\", \"sku\", \"skus\", \"search_term\", \"staticpage\", \"campaign_source\", \"search_engine\", \"screen_resolution\", \"browser_version\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessionsTrain = train.sort_values(by = [\"person\", \"timestamp\"])\n",
    "eventsWithSessionsKaggle = kaggle.sort_values(by = [\"person\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrimerIngresoTrain =  eventsWithSessionsTrain.groupby(\"person\")[\"timestamp\"].first().reset_index()\n",
    "dataPrimerIngresoKaggle =  eventsWithSessionsKaggle.groupby(\"person\")[\"timestamp\"].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = '2018-06-01' \n",
    "format_str = '%Y-%m-%d'\n",
    "finalDate = datetime.strptime(date_str, format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrimerIngresoTrain[\"primerIngreso\"] = (finalDate - dataPrimerIngresoTrain.timestamp)\n",
    "dataPrimerIngresoTrain[\"primerIngreso\"] = dataPrimerIngresoTrain[\"primerIngreso\"].map(lambda x: x.days)\n",
    "dataPrimerIngresoTrain = dataPrimerIngresoTrain.drop(\"timestamp\", axis=1)\n",
    "\n",
    "dataPrimerIngresoKaggle[\"primerIngreso\"] = (finalDate - dataPrimerIngresoKaggle.timestamp)\n",
    "dataPrimerIngresoKaggle[\"primerIngreso\"] = dataPrimerIngresoKaggle[\"primerIngreso\"].map(lambda x: x.days)\n",
    "dataPrimerIngresoKaggle = dataPrimerIngresoKaggle.drop(\"timestamp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessionsTrain = pd.merge(eventsWithSessionsTrain, dataPrimerIngresoTrain, how = \"left\", on = \"person\")\n",
    "eventsWithSessionsKaggle = pd.merge(eventsWithSessionsKaggle, dataPrimerIngresoKaggle, how = \"left\", on = \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventsWithSessionsTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empezamos con las sesiones.\n",
    "\n",
    "eventsWithSessionsTrain[\"time_diff\"] = (eventsWithSessionsTrain.timestamp - (eventsWithSessionsTrain.timestamp.shift())) / np.timedelta64(1, 's')\n",
    "eventsWithSessionsTrain.loc[eventsWithSessionsTrain.person != eventsWithSessionsTrain.person.shift(), \"time_diff\"] = 0\n",
    "\n",
    "eventsWithSessionsKaggle[\"time_diff\"] = (eventsWithSessionsKaggle.timestamp - (eventsWithSessionsKaggle.timestamp.shift())) / np.timedelta64(1, 's')\n",
    "eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle.person != eventsWithSessionsKaggle.person.shift(), \"time_diff\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessionsTrain[\"session_change\"] = ((eventsWithSessionsTrain.event == \"visited site\") & (eventsWithSessionsTrain.time_diff > 1800.0)) | (eventsWithSessionsTrain.time_diff > 36000.0) | (eventsWithSessionsTrain.person != eventsWithSessionsTrain.person.shift())\n",
    "eventsWithSessionsTrain[\"session_id\"] = eventsWithSessionsTrain.groupby(\"person\")[\"session_change\"].cumsum()\n",
    "\n",
    "eventsWithSessionsKaggle[\"session_change\"] = ((eventsWithSessionsKaggle.event == \"visited site\") & (eventsWithSessionsKaggle.time_diff > 1800.0)) | (eventsWithSessionsKaggle.time_diff > 36000.0) | (eventsWithSessionsKaggle.person != eventsWithSessionsKaggle.person.shift())\n",
    "eventsWithSessionsKaggle[\"session_id\"] = eventsWithSessionsKaggle.groupby(\"person\")[\"session_change\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Obtener las personas con conversiones\n",
    "# dataConversionTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain['event'] == 'conversion']\n",
    "# personasCompraronTrain = dataConversionTrain.drop_duplicates(subset = 'person', keep = 'first')['person'].tolist()\n",
    "# dataPersonasCompraronTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain['person'].isin(personasCompraronTrain)]\n",
    "\n",
    "# dataConversionKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle['event'] == 'conversion']\n",
    "# personasCompraronKaggle = dataConversionKaggle.drop_duplicates(subset = 'person', keep = 'first')['person'].tolist()\n",
    "# dataPersonasCompraronKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle['person'].isin(personasCompraronKaggle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataPersonasCompraron[\"aConversion\"] = (dataPersonasCompraron.event == \"conversion\") | (dataPersonasCompraron.person != dataPersonasCompraron.person.shift())\n",
    "# dataPersonasCompraron[\"conversions\"] = dataPersonasCompraron.groupby(\"person\")[\"aConversion\"].cumsum()\n",
    "# dataFirstConversion = dataPersonasCompraron.loc[dataPersonasCompraron.conversions == 1.0].groupby(\"person\", as_index= False)[\"time_diff\"].agg({\"timeFirstConversion\": \"sum\" })\n",
    "# eventsWithSessions = pd.merge(eventsWithSessions, dataFirstConversion, how='left', on = 'person')\n",
    "# eventsWithSessions['timeFirstConversion'] = eventsWithSessions['timeFirstConversion'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSessionTrain =  eventsWithSessionsTrain.groupby([\"person\", \"session_id\"], as_index=False)[\"time_diff\"].agg({\"sessionDuration\": \"sum\" })\n",
    "dataSessionTrain[\"sessionDuration\"] = dataSessionTrain[\"sessionDuration\"]/60\n",
    "\n",
    "dataSessionKaggle =  eventsWithSessionsKaggle.groupby([\"person\", \"session_id\"], as_index=False)[\"time_diff\"].agg({\"sessionDuration\": \"sum\" })\n",
    "dataSessionKaggle[\"sessionDuration\"] = dataSessionKaggle[\"sessionDuration\"]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSessionGroupByPersonTrain = dataSessionTrain.loc[dataSessionTrain.sessionDuration > 0.0].groupby(\"person\", as_index = False)\n",
    "dataSessionTrain = dataSessionGroupByPersonTrain.agg({\"sessionDuration\": {\"sessionDuration\": \"mean\"}, \"session_id\": {\"cantSessions\": \"count\"}})\n",
    "dataSessionTrain.columns = [\"person\", \"cantSessions\", \"sessionDuration\"]\n",
    "\n",
    "dataSessionGroupByPersonKaggle = dataSessionKaggle.loc[dataSessionKaggle.sessionDuration > 0.0].groupby(\"person\", as_index = False)\n",
    "dataSessionKaggle = dataSessionGroupByPersonKaggle.agg({\"sessionDuration\": {\"sessionDuration\": \"mean\"}, \"session_id\": {\"cantSessions\": \"count\"}})\n",
    "dataSessionKaggle.columns = [\"person\", \"cantSessions\", \"sessionDuration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eventsWithSessionsTrain = pd.merge(eventsWithSessionsTrain, dataSessionTrain, how ='left', on = \"person\")\n",
    "eventsWithSessionsTrain[\"sessionDuration\"] = eventsWithSessionsTrain[\"sessionDuration\"].fillna(value = 0.0)\n",
    "eventsWithSessionsTrain[\"cantSessions\"] = eventsWithSessionsTrain[\"cantSessions\"].fillna(value = 0.0)\n",
    "\n",
    "eventsWithSessionsKaggle = pd.merge(eventsWithSessionsKaggle, dataSessionKaggle, how ='left', on = \"person\")\n",
    "eventsWithSessionsKaggle[\"sessionDuration\"] = eventsWithSessionsKaggle[\"sessionDuration\"].fillna(value = 0.0)\n",
    "eventsWithSessionsKaggle[\"cantSessions\"] = eventsWithSessionsKaggle[\"cantSessions\"].fillna(value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que realiza el oneHotEncoding\n",
    "def oneHotEncoding(column, uniqueArray, dataFrame):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(uniqueArray)\n",
    "    integer_encoded = label_encoder.transform(dataFrame[column])\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    for i, item in enumerate(uniqueArray):\n",
    "        dataFrame[item] = onehot_encoded[:, label_encoder.transform(uniqueArray)[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsColorTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain[\"color\"].notnull()][[\"color\", \"person\"]]\n",
    "eventsConditionTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain[\"condition\"].notnull()][[\"condition\", \"person\"]]\n",
    "eventsStorageTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain[\"storage\"].notnull()][[\"storage\", \"person\"]]\n",
    "eventsModelTrain = eventsWithSessionsTrain.loc[(eventsWithSessionsTrain[\"model\"].notnull())][[\"model\", \"person\"]]\n",
    "eventsChannelTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain[\"channel\"] != \"Unknown\"][[\"channel\", \"person\"]]\n",
    "eventsDeviceTrain = eventsWithSessionsTrain.loc[eventsWithSessionsTrain[\"device_type\"] != \"Unknown\"][[\"device_type\", \"person\"]]\n",
    "\n",
    "eventsColorKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle[\"color\"].notnull()][[\"color\", \"person\"]]\n",
    "eventsConditionKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle[\"condition\"].notnull()][[\"condition\", \"person\"]]\n",
    "eventsStorageKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle[\"storage\"].notnull()][[\"storage\", \"person\"]]\n",
    "eventsModelKaggle = eventsWithSessionsKaggle.loc[(eventsWithSessionsKaggle[\"model\"].notnull())][[\"model\", \"person\"]]\n",
    "eventsChannelKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle[\"channel\"] != \"Unknown\"][[\"channel\", \"person\"]]\n",
    "eventsDeviceKaggle = eventsWithSessionsKaggle.loc[eventsWithSessionsKaggle[\"device_type\"] != \"Unknown\"][[\"device_type\", \"person\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventsColor[\"color\"] = eventsColor.color.str.split(\" \", expand=True)\n",
    "# top20Colors = eventsColor['color'].value_counts().nlargest(20).index\n",
    "# top50models = eventsWithLabel3['model'].value_counts().nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def colorGrouping(x):\n",
    "#     return x if x in top20Colors else 'OtroColor'\n",
    "\n",
    "# def modelGrouping(x):\n",
    "#     return x if x in top50models else 'OtroModelo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventsColor['color'] = eventsColor['color'].apply(colorGrouping)\n",
    "# eventsModel['model'] = eventsModel['model'].apply(modelGrouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventosUnicosTrain = eventsWithSessionsTrain.drop_duplicates(subset=\"event\", keep=\"first\").reset_index()[\"event\"]\n",
    "coloresUnicosTrain = eventsColorTrain.drop_duplicates(subset='color', keep='first').reset_index()[\"color\"]\n",
    "conditionUnicosTrain = eventsConditionTrain.drop_duplicates(subset='condition', keep='first').reset_index()[\"condition\"]\n",
    "storageUnicosTrain = eventsStorageTrain.drop_duplicates(subset='storage', keep='first').reset_index()[\"storage\"]\n",
    "modelosUnicosTrain = eventsModelTrain.drop_duplicates(subset='model', keep='first').reset_index()['model']\n",
    "channelUnicosTrain = eventsChannelTrain.drop_duplicates(subset=\"channel\", keep=\"first\").reset_index()[\"channel\"]\n",
    "# SOUnicosTrain = eventsWithSessionsTrain.drop_duplicates(subset=\"SO\", keep=\"first\").reset_index()[\"SO\"]\n",
    "deviceTypeUnicosTrain = eventsDeviceTrain.drop_duplicates(subset=\"device_type\", keep=\"first\").reset_index()[\"device_type\"]\n",
    "daysWeekUnicosTrain = eventsWithSessionsTrain.drop_duplicates(subset=\"dayweek\", keep=\"first\").reset_index()[\"dayweek\"]\n",
    "monthUnicosTrain = eventsWithSessionsTrain.drop_duplicates(subset=\"month\", keep=\"first\").reset_index()[\"month\"]\n",
    "\n",
    "eventosUnicosKaggle = eventsWithSessionsKaggle.drop_duplicates(subset=\"event\", keep=\"first\").reset_index()[\"event\"]\n",
    "coloresUnicosKaggle = eventsColorKaggle.drop_duplicates(subset='color', keep='first').reset_index()[\"color\"]\n",
    "conditionUnicosKaggle = eventsConditionKaggle.drop_duplicates(subset='condition', keep='first').reset_index()[\"condition\"]\n",
    "storageUnicosKaggle = eventsStorageKaggle.drop_duplicates(subset='storage', keep='first').reset_index()[\"storage\"]\n",
    "modelosUnicosKaggle = eventsModelKaggle.drop_duplicates(subset='model', keep='first').reset_index()['model']\n",
    "channelUnicosKaggle = eventsChannelKaggle.drop_duplicates(subset=\"channel\", keep=\"first\").reset_index()[\"channel\"]\n",
    "# SOUnicosKaggle = eventsWithSessionsKaggle.drop_duplicates(subset=\"SO\", keep=\"first\").reset_index()[\"SO\"]\n",
    "deviceTypeUnicosKaggle = eventsDeviceKaggle.drop_duplicates(subset=\"device_type\", keep=\"first\").reset_index()[\"device_type\"]\n",
    "daysWeekUnicosKaggle = eventsWithSessionsKaggle.drop_duplicates(subset=\"dayweek\", keep=\"first\").reset_index()[\"dayweek\"]\n",
    "monthUnicosKaggle = eventsWithSessionsKaggle.drop_duplicates(subset=\"month\", keep=\"first\").reset_index()[\"month\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoding(\"event\", eventosUnicosTrain, eventsWithSessionsTrain)\n",
    "oneHotEncoding(\"color\", coloresUnicosTrain, eventsColorTrain)\n",
    "oneHotEncoding(\"condition\", conditionUnicosTrain, eventsConditionTrain)\n",
    "oneHotEncoding(\"storage\", storageUnicosTrain, eventsStorageTrain)\n",
    "oneHotEncoding(\"model\", modelosUnicosTrain, eventsModelTrain)\n",
    "oneHotEncoding(\"channel\", channelUnicosTrain, eventsChannelTrain)\n",
    "# oneHotEncoding(\"SO\", SOUnicosTrain, eventsWithSessionsTrain)\n",
    "oneHotEncoding(\"device_type\", deviceTypeUnicosTrain, eventsDeviceTrain)\n",
    "oneHotEncoding(\"dayweek\", daysWeekUnicosTrain, eventsWithSessionsTrain)\n",
    "oneHotEncoding(\"month\", monthUnicosTrain, eventsWithSessionsTrain)\n",
    "\n",
    "\n",
    "oneHotEncoding(\"event\", eventosUnicosKaggle, eventsWithSessionsKaggle)\n",
    "oneHotEncoding(\"color\", coloresUnicosKaggle, eventsColorKaggle)\n",
    "oneHotEncoding(\"condition\", conditionUnicosKaggle, eventsConditionKaggle)\n",
    "oneHotEncoding(\"storage\", storageUnicosKaggle, eventsStorageKaggle)\n",
    "oneHotEncoding(\"model\", modelosUnicosKaggle, eventsModelKaggle)\n",
    "oneHotEncoding(\"channel\", channelUnicosKaggle, eventsChannelKaggle)\n",
    "# oneHotEncoding(\"SO\", SOUnicosKaggle, eventsWithSessionsKaggle)\n",
    "oneHotEncoding(\"device_type\", deviceTypeUnicosKaggle, eventsDeviceKaggle)\n",
    "oneHotEncoding(\"dayweek\", daysWeekUnicosKaggle, eventsWithSessionsKaggle)\n",
    "oneHotEncoding(\"month\", monthUnicosKaggle, eventsWithSessionsKaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessions2Train = eventsWithSessionsTrain.drop([\"timestamp\", \"dayweek\", \"month\", \"event\", \"cantEventos\",\"condition\", \"model\", \"storage\", \"color\", \"fecha\", \"SO\", \"marca\", \"city\", \"country\", \"channel\", \"device_type\", \"session_id\", \"session_change\", \"time_diff\"], axis = 1)\n",
    "\n",
    "eventsWithSessions2Kaggle = eventsWithSessionsKaggle.drop([\"timestamp\", \"dayweek\", \"month\", \"event\", \"cantEventos\",\"condition\", \"model\", \"storage\", \"color\", \"fecha\", \"SO\", \"marca\", \"city\", \"country\", \"channel\", \"device_type\", \"session_id\", \"session_change\", \"time_diff\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsFinaleTrain = eventsWithSessions2Train\n",
    "eventsFinaleKaggle = eventsWithSessions2Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventosUnicosWithPersonTrain = eventosUnicosTrain.values\n",
    "eventosUnicosWithPersonTrain = eventosUnicosWithPersonTrain.tolist()\n",
    "eventosUnicosWithPersonTrain.append(\"person\")\n",
    "\n",
    "eventosUnicosWithPersonKaggle = eventosUnicosKaggle.values\n",
    "eventosUnicosWithPersonKaggle = eventosUnicosWithPersonKaggle.tolist()\n",
    "eventosUnicosWithPersonKaggle.append(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsFinaleTrain = eventsFinaleTrain.loc[:, eventosUnicosWithPersonTrain]\n",
    "eventsFinaleFilterTrain = eventsFinaleTrain.groupby(\"person\").sum()\n",
    "\n",
    "eventsFinaleKaggle = eventsFinaleKaggle.loc[:, eventosUnicosWithPersonTrain]\n",
    "eventsFinaleFilterKaggle = eventsFinaleKaggle.groupby(\"person\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsColor1Train = eventsColorTrain.groupby(\"person\").sum()\n",
    "eventsCondition1Train = eventsConditionTrain.groupby(\"person\").sum()\n",
    "eventsDevice1Train = eventsDeviceTrain.groupby(\"person\").sum()\n",
    "eventsModel1Train = eventsModelTrain.groupby(\"person\").sum()\n",
    "eventsStorage1Train = eventsStorageTrain.groupby(\"person\").sum()\n",
    "eventsChannel1Train = eventsChannelTrain.groupby(\"person\").sum()\n",
    "\n",
    "eventsColor1Kaggle = eventsColorKaggle.groupby(\"person\").sum()\n",
    "eventsCondition1Kaggle = eventsConditionKaggle.groupby(\"person\").sum()\n",
    "eventsDevice1Kaggle = eventsDeviceKaggle.groupby(\"person\").sum()\n",
    "eventsModel1Kaggle = eventsModelKaggle.groupby(\"person\").sum()\n",
    "eventsStorage1Kaggle = eventsStorageKaggle.groupby(\"person\").sum()\n",
    "eventsChannel1Kaggle = eventsChannelKaggle.groupby(\"person\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessionsFilterTrain = eventsWithSessions2Train.drop(columns= eventosUnicosTrain).groupby(\"person\").first()\n",
    "eventsWithSessionsFilterKaggle = eventsWithSessions2Kaggle.drop(columns= eventosUnicosKaggle).groupby(\"person\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsWithSessionsFilterTrain[\"regionMorePurchase\"] = eventsWithSessionsFilterTrain[\"region\"].map(lambda x: 1 if x in regionesMasCompras else 0) \n",
    "eventsWithSessionsFilterKaggle[\"regionMorePurchase\"] = eventsWithSessionsFilterKaggle[\"region\"].map(lambda x: 1 if x in regionesMasCompras else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eventsWithSessionsFilterTrain = eventsWithSessionsFilterTrain.drop(\"region\", axis=1)\n",
    "eventsWithSessionsFilterKaggle = eventsWithSessionsFilterKaggle.drop(\"region\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.merge(eventsWithSessionsFilterTrain, eventsFinaleFilterTrain, on = \"person\")\n",
    "# trainDF = pd.merge(trainDF, eventsModel1Train , how=\"left\", on = \"person\")\n",
    "# trainDF = pd.merge(trainDF, eventsColor1Train, how=\"left\" , on = \"person\")\n",
    "# trainDF = pd.merge(trainDF, eventsChannel1Train, how=\"left\" , on = \"person\")\n",
    "# trainDF = pd.merge(trainDF, eventsCondition1Train, how=\"left\" , on = \"person\")\n",
    "trainDF = pd.merge(trainDF, eventsDevice1Train, how=\"left\" , on = \"person\")\n",
    "trainDF = pd.merge(trainDF, eventsStorage1Train, how=\"left\" , on = \"person\")\n",
    "\n",
    "kaggleDF = pd.merge(eventsWithSessionsFilterKaggle, eventsFinaleFilterKaggle, on = \"person\")\n",
    "# kaggleDF = pd.merge(kaggleDF, eventsModel1Kaggle , how=\"left\", on = \"person\")\n",
    "# kaggleDF = pd.merge(kaggleDF, eventsColor1Kaggle, how=\"left\" , on = \"person\")\n",
    "# kaggleDF = pd.merge(kaggleDF, eventsChannel1Kaggle, how=\"left\" , on = \"person\")\n",
    "# kaggleDF = pd.merge(kaggleDF, eventsCondition1Kaggle, how=\"left\" , on = \"person\")\n",
    "kaggleDF = pd.merge(kaggleDF, eventsDevice1Kaggle, how=\"left\" , on = \"person\")\n",
    "kaggleDF = pd.merge(kaggleDF, eventsStorage1Kaggle, how=\"left\" , on = \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDF = trainDF.fillna(value=0)\n",
    "kaggleDF = kaggleDF.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_values = scaler.fit_transform(trainDF)\n",
    "# trainDF.loc[:, :] = scaled_values\n",
    "# scaled_values = scaler.fit_transform(testDFFinal)\n",
    "# testDFFinal.loc[:, :] = scaled_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos los csv ya listo para entrenar a los algoritmos y para testear que tan buenos son.\n",
    "trainDF.to_csv('setEntrenamiento.csv')\n",
    "kaggleDF.to_csv('setKaggle.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
