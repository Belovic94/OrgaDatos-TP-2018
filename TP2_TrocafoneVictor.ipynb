{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "training = pd.read_csv('setEntrenamiento.csv', low_memory = False)\n",
    "kaggle = pd.read_csv('setKaggle.csv', low_memory = False)\n",
    "kaggle = kaggle.drop(\"Unnamed: 34\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, classification_report, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_array = np.array(training['label'])\n",
    "data_array = np.array(training.drop(columns=['label', 'person']))\n",
    "kaggle_data = np.array(kaggle.drop(columns=['person']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = training.drop(columns=['label', 'person'])\n",
    "kaggleF = kaggle.drop(\"person\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(train)\n",
    "train.loc[:, :] = scaled_values\n",
    "scaled_values = scaler.fit_transform(kaggleF)\n",
    "kaggleF.loc[:, :] = scaled_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitasProm</th>\n",
       "      <th>returning</th>\n",
       "      <th>pastConversions</th>\n",
       "      <th>primerIngreso</th>\n",
       "      <th>cantSessions</th>\n",
       "      <th>sessionDuration</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>...</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Tablet</th>\n",
       "      <th>32GB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>128GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.649933</td>\n",
       "      <td>-1.095288</td>\n",
       "      <td>-0.242065</td>\n",
       "      <td>-0.326531</td>\n",
       "      <td>-0.417802</td>\n",
       "      <td>-0.294810</td>\n",
       "      <td>2.173228</td>\n",
       "      <td>-0.474926</td>\n",
       "      <td>-0.317055</td>\n",
       "      <td>-0.384643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342069</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>-0.277459</td>\n",
       "      <td>-0.252084</td>\n",
       "      <td>-0.220210</td>\n",
       "      <td>-0.145643</td>\n",
       "      <td>-0.243935</td>\n",
       "      <td>-0.361089</td>\n",
       "      <td>-0.130657</td>\n",
       "      <td>-0.091045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015830</td>\n",
       "      <td>-1.095288</td>\n",
       "      <td>-0.242065</td>\n",
       "      <td>-0.706491</td>\n",
       "      <td>-0.428985</td>\n",
       "      <td>-0.427776</td>\n",
       "      <td>-0.460145</td>\n",
       "      <td>2.105593</td>\n",
       "      <td>-0.317055</td>\n",
       "      <td>-0.384643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120293</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>-0.337554</td>\n",
       "      <td>-0.302599</td>\n",
       "      <td>0.117743</td>\n",
       "      <td>-0.145643</td>\n",
       "      <td>-0.243935</td>\n",
       "      <td>-0.361089</td>\n",
       "      <td>-0.130657</td>\n",
       "      <td>-0.091045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.136877</td>\n",
       "      <td>-1.095288</td>\n",
       "      <td>-0.242065</td>\n",
       "      <td>-0.769818</td>\n",
       "      <td>-0.428941</td>\n",
       "      <td>-0.427776</td>\n",
       "      <td>2.173228</td>\n",
       "      <td>-0.474926</td>\n",
       "      <td>-0.317055</td>\n",
       "      <td>-0.384643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094201</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>-0.337554</td>\n",
       "      <td>-0.151054</td>\n",
       "      <td>-0.220210</td>\n",
       "      <td>0.470973</td>\n",
       "      <td>-0.243935</td>\n",
       "      <td>-0.361089</td>\n",
       "      <td>-0.130657</td>\n",
       "      <td>-0.091045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.023120</td>\n",
       "      <td>0.913002</td>\n",
       "      <td>2.513731</td>\n",
       "      <td>3.124779</td>\n",
       "      <td>0.856436</td>\n",
       "      <td>1.167811</td>\n",
       "      <td>-0.460145</td>\n",
       "      <td>-0.474926</td>\n",
       "      <td>3.154031</td>\n",
       "      <td>-0.384643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342069</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>0.083108</td>\n",
       "      <td>-0.302599</td>\n",
       "      <td>-0.220210</td>\n",
       "      <td>-0.145643</td>\n",
       "      <td>9.049878</td>\n",
       "      <td>2.723209</td>\n",
       "      <td>-0.130657</td>\n",
       "      <td>-0.091045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.484868</td>\n",
       "      <td>0.913002</td>\n",
       "      <td>-0.242065</td>\n",
       "      <td>2.016560</td>\n",
       "      <td>0.400665</td>\n",
       "      <td>1.300776</td>\n",
       "      <td>-0.460145</td>\n",
       "      <td>-0.474926</td>\n",
       "      <td>3.154031</td>\n",
       "      <td>-0.384643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>-0.007033</td>\n",
       "      <td>0.202551</td>\n",
       "      <td>0.455695</td>\n",
       "      <td>1.087588</td>\n",
       "      <td>-0.243935</td>\n",
       "      <td>0.268360</td>\n",
       "      <td>-0.130657</td>\n",
       "      <td>-0.091045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitasProm  returning  pastConversions  primerIngreso  cantSessions  \\\n",
       "0    -0.649933  -1.095288        -0.242065      -0.326531     -0.417802   \n",
       "1     0.015830  -1.095288        -0.242065      -0.706491     -0.428985   \n",
       "2     0.136877  -1.095288        -0.242065      -0.769818     -0.428941   \n",
       "3     1.023120   0.913002         2.513731       3.124779      0.856436   \n",
       "4    -0.484868   0.913002        -0.242065       2.016560      0.400665   \n",
       "\n",
       "   sessionDuration  Thursday   Tuesday    Sunday    Friday    ...     \\\n",
       "0        -0.294810  2.173228 -0.474926 -0.317055 -0.384643    ...      \n",
       "1        -0.427776 -0.460145  2.105593 -0.317055 -0.384643    ...      \n",
       "2        -0.427776  2.173228 -0.474926 -0.317055 -0.384643    ...      \n",
       "3         1.167811 -0.460145 -0.474926  3.154031 -0.384643    ...      \n",
       "4         1.300776 -0.460145 -0.474926  3.154031 -0.384643    ...      \n",
       "\n",
       "   Smartphone    Tablet      32GB      64GB     128GB     256GB       8GB  \\\n",
       "0   -0.342069 -0.059506 -0.277459 -0.252084 -0.220210 -0.145643 -0.243935   \n",
       "1   -0.120293 -0.059506 -0.337554 -0.302599  0.117743 -0.145643 -0.243935   \n",
       "2   -0.094201 -0.059506 -0.337554 -0.151054 -0.220210  0.470973 -0.243935   \n",
       "3   -0.342069 -0.059506  0.083108 -0.302599 -0.220210 -0.145643  9.049878   \n",
       "4    0.910314 -0.059506 -0.007033  0.202551  0.455695  1.087588 -0.243935   \n",
       "\n",
       "       16GB       4GB     512MB  \n",
       "0 -0.361089 -0.130657 -0.091045  \n",
       "1 -0.361089 -0.130657 -0.091045  \n",
       "2 -0.361089 -0.130657 -0.091045  \n",
       "3  2.723209 -0.130657 -0.091045  \n",
       "4  0.268360 -0.130657 -0.091045  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitasProm</th>\n",
       "      <th>returning</th>\n",
       "      <th>pastConversions</th>\n",
       "      <th>primerIngreso</th>\n",
       "      <th>cantSessions</th>\n",
       "      <th>sessionDuration</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>...</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Tablet</th>\n",
       "      <th>32GB</th>\n",
       "      <th>128GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.252685</td>\n",
       "      <td>0.914959</td>\n",
       "      <td>-0.148354</td>\n",
       "      <td>0.117482</td>\n",
       "      <td>-0.271250</td>\n",
       "      <td>2.964432</td>\n",
       "      <td>2.168003</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>-0.301418</td>\n",
       "      <td>-0.403896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336980</td>\n",
       "      <td>-0.06146</td>\n",
       "      <td>3.815207</td>\n",
       "      <td>4.476763</td>\n",
       "      <td>3.085243</td>\n",
       "      <td>4.120833</td>\n",
       "      <td>4.253848</td>\n",
       "      <td>-0.238049</td>\n",
       "      <td>-0.094756</td>\n",
       "      <td>-0.066211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.385829</td>\n",
       "      <td>-1.092945</td>\n",
       "      <td>-0.148354</td>\n",
       "      <td>1.304347</td>\n",
       "      <td>-0.428608</td>\n",
       "      <td>-0.428948</td>\n",
       "      <td>-0.461254</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>-0.301418</td>\n",
       "      <td>2.475884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202483</td>\n",
       "      <td>-0.06146</td>\n",
       "      <td>-0.342100</td>\n",
       "      <td>-0.148227</td>\n",
       "      <td>-0.338740</td>\n",
       "      <td>-0.264750</td>\n",
       "      <td>-0.193948</td>\n",
       "      <td>-0.238049</td>\n",
       "      <td>-0.094756</td>\n",
       "      <td>-0.066211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.228686</td>\n",
       "      <td>0.914959</td>\n",
       "      <td>0.723932</td>\n",
       "      <td>-0.319785</td>\n",
       "      <td>-0.095073</td>\n",
       "      <td>-0.021743</td>\n",
       "      <td>2.168003</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>-0.301418</td>\n",
       "      <td>-0.403896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336980</td>\n",
       "      <td>-0.06146</td>\n",
       "      <td>0.287795</td>\n",
       "      <td>-0.246631</td>\n",
       "      <td>3.450911</td>\n",
       "      <td>-0.264750</td>\n",
       "      <td>0.250831</td>\n",
       "      <td>1.919249</td>\n",
       "      <td>0.555078</td>\n",
       "      <td>-0.066211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.811631</td>\n",
       "      <td>0.914959</td>\n",
       "      <td>-0.148354</td>\n",
       "      <td>-0.288551</td>\n",
       "      <td>-0.219587</td>\n",
       "      <td>0.792668</td>\n",
       "      <td>-0.461254</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>-0.301418</td>\n",
       "      <td>-0.403896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336980</td>\n",
       "      <td>-0.06146</td>\n",
       "      <td>6.240302</td>\n",
       "      <td>-0.148227</td>\n",
       "      <td>3.218214</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>0.250831</td>\n",
       "      <td>-0.238049</td>\n",
       "      <td>-0.094756</td>\n",
       "      <td>-0.066211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045448</td>\n",
       "      <td>0.914959</td>\n",
       "      <td>-0.148354</td>\n",
       "      <td>-0.257318</td>\n",
       "      <td>-0.321751</td>\n",
       "      <td>-0.021743</td>\n",
       "      <td>-0.461254</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>-0.301418</td>\n",
       "      <td>-0.403896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336980</td>\n",
       "      <td>-0.06146</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>-0.246631</td>\n",
       "      <td>-0.106042</td>\n",
       "      <td>-0.153723</td>\n",
       "      <td>0.250831</td>\n",
       "      <td>0.350305</td>\n",
       "      <td>-0.094756</td>\n",
       "      <td>-0.066211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitasProm  returning  pastConversions  primerIngreso  cantSessions  \\\n",
       "0     0.252685   0.914959        -0.148354       0.117482     -0.271250   \n",
       "1    -0.385829  -1.092945        -0.148354       1.304347     -0.428608   \n",
       "2     3.228686   0.914959         0.723932      -0.319785     -0.095073   \n",
       "3     1.811631   0.914959        -0.148354      -0.288551     -0.219587   \n",
       "4     0.045448   0.914959        -0.148354      -0.257318     -0.321751   \n",
       "\n",
       "   sessionDuration  Thursday  Saturday    Sunday    Monday    ...     \\\n",
       "0         2.964432  2.168003 -0.332713 -0.301418 -0.403896    ...      \n",
       "1        -0.428948 -0.461254 -0.332713 -0.301418  2.475884    ...      \n",
       "2        -0.021743  2.168003 -0.332713 -0.301418 -0.403896    ...      \n",
       "3         0.792668 -0.461254 -0.332713 -0.301418 -0.403896    ...      \n",
       "4        -0.021743 -0.461254 -0.332713 -0.301418 -0.403896    ...      \n",
       "\n",
       "   Smartphone   Tablet      32GB     128GB      16GB      64GB     256GB  \\\n",
       "0   -0.336980 -0.06146  3.815207  4.476763  3.085243  4.120833  4.253848   \n",
       "1   -0.202483 -0.06146 -0.342100 -0.148227 -0.338740 -0.264750 -0.193948   \n",
       "2   -0.336980 -0.06146  0.287795 -0.246631  3.450911 -0.264750  0.250831   \n",
       "3   -0.336980 -0.06146  6.240302 -0.148227  3.218214  0.845524  0.250831   \n",
       "4   -0.336980 -0.06146  0.004343 -0.246631 -0.106042 -0.153723  0.250831   \n",
       "\n",
       "        8GB       4GB     512MB  \n",
       "0 -0.238049 -0.094756 -0.066211  \n",
       "1 -0.238049 -0.094756 -0.066211  \n",
       "2  1.919249  0.555078 -0.066211  \n",
       "3 -0.238049 -0.094756 -0.066211  \n",
       "4  0.350305 -0.094756 -0.066211  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggleF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(train.drop(columns=[\"sessionDuration\"]))\n",
    "kaggle_data = np.array(kaggleF.drop(columns=['sessionDuration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78694203 0.76399337 0.75907966 0.79791702 0.75452297 0.74301497\n",
      " 0.74131379 0.71753145 0.80812814 0.77649314]\n"
     ]
    }
   ],
   "source": [
    "#CrossValidation ExtraTree\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label_array, test_size = 0, random_state = 0)\n",
    "etx = ExtraTreesClassifier(n_estimators = 200, random_state= 0)\n",
    "all_accuracies5 = cross_val_score(estimator = etx, X= x_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(all_accuracies5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007261697990307\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies5.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8070241734151393\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies5.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015837682374172008\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies5.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82807583 0.81143532 0.8468685  0.85307809 0.83073031 0.81667093\n",
      " 0.83777797 0.80230894 0.86340348 0.87651018]\n"
     ]
    }
   ],
   "source": [
    "#CrossValidation RandomForest\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label_array, test_size = 0, random_state = 0)\n",
    "rf = RandomForestClassifier(n_estimators = 200, random_state= 0)\n",
    "all_accuracies1 = cross_val_score(estimator = rf, X= x_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(all_accuracies1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8322093518754266\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366859545348673\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019256258308148644\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82394307 0.8267049  0.85382583 0.87229437 0.84907798 0.84319673\n",
      " 0.85406833 0.82924086 0.87886456 0.88741586]\n"
     ]
    }
   ],
   "source": [
    "#CrossValidation XGBoost\n",
    "# subsample = 0.8 learning_rate = 0.1, colsample_bytree = 0.6\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label_array, test_size = 0, random_state = 0)\n",
    "xgb = XGBClassifier(n_estimators = 45, max_depth = 7, subsample = 0.8)\n",
    "all_accuracies2 = cross_val_score(estimator = xgb, X= x_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(all_accuracies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8515658047462231\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8518632488872717\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021038825980603845\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74098152 0.69828526 0.80238939 0.77075392 0.73084275 0.78271563\n",
      " 0.8004828  0.73188492 0.80383971 0.80879839]\n"
     ]
    }
   ],
   "source": [
    "#Neuronal Networks\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label_array, test_size = 0, random_state = 0)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13), max_iter = 500)\n",
    "all_accuracies4 = cross_val_score(estimator = mlp, X= x_train, y = y_train, cv = 10, scoring=\"roc_auc\")\n",
    "print(all_accuracies4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765048267051537\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies4.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"hidden_layer_sizes\":[(10, 10, 10), (11, 11, 11), (12, 12, 12), (15, 15 ,15)], \n",
    "        \"max_iter\":[500, 600, 700, 800]}\n",
    "gd_nn = GridSearchCV(estimator=mlp, param_grid=grid, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_nn.fit(x_train_nn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(data_array, label_array, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=45,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Fit\n",
    "xgb.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Predcit_proba\n",
    "y_pred_xgb = xgb.predict_proba(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510886378128353"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test1, y_pred_xgb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etx.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = etx.predict(x_test1)\n",
    "y_pred1Prob = etx.predict_proba(x_test1)\n",
    "y_pred2 = xgb.predict(x_test1)\n",
    "y_pred2Prob = xgb.predict_proba(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "51\n",
      "59\n",
      "147\n",
      "151\n",
      "157\n",
      "166\n",
      "183\n",
      "186\n",
      "231\n",
      "236\n",
      "258\n",
      "276\n",
      "309\n",
      "310\n",
      "385\n",
      "401\n",
      "405\n",
      "408\n",
      "421\n",
      "426\n",
      "438\n",
      "450\n",
      "491\n",
      "493\n",
      "532\n",
      "563\n",
      "605\n",
      "613\n",
      "626\n",
      "627\n",
      "630\n",
      "637\n",
      "662\n",
      "673\n",
      "688\n",
      "702\n",
      "713\n",
      "744\n",
      "783\n",
      "802\n",
      "809\n",
      "880\n",
      "895\n",
      "900\n",
      "903\n",
      "940\n",
      "977\n",
      "987\n",
      "1040\n",
      "1044\n",
      "1048\n",
      "1053\n",
      "1056\n",
      "1059\n",
      "1082\n",
      "1136\n",
      "1204\n",
      "1206\n",
      "1224\n",
      "1227\n",
      "1244\n",
      "1268\n",
      "1282\n",
      "1297\n",
      "1299\n",
      "1331\n",
      "1361\n",
      "1365\n",
      "1400\n",
      "1429\n",
      "1437\n",
      "1465\n",
      "1478\n",
      "1484\n",
      "1489\n",
      "1491\n",
      "1518\n",
      "1544\n",
      "1581\n",
      "1605\n",
      "1607\n",
      "1608\n",
      "1625\n",
      "1647\n",
      "1674\n",
      "1709\n",
      "1774\n",
      "1789\n",
      "1807\n",
      "1808\n",
      "1848\n",
      "1856\n",
      "1867\n",
      "1882\n",
      "1905\n",
      "1943\n",
      "1979\n",
      "1984\n",
      "2002\n",
      "2029\n",
      "2045\n",
      "2204\n",
      "2212\n",
      "2223\n",
      "2235\n",
      "2240\n",
      "2254\n",
      "2262\n",
      "2275\n",
      "2322\n",
      "2330\n",
      "2338\n",
      "2362\n",
      "2395\n",
      "2400\n",
      "2402\n",
      "2465\n",
      "2471\n",
      "2515\n",
      "2533\n",
      "2621\n",
      "2640\n",
      "2681\n",
      "2731\n",
      "2732\n",
      "2748\n",
      "2774\n",
      "2784\n",
      "2806\n",
      "2808\n",
      "2816\n",
      "2840\n",
      "2871\n",
      "2880\n",
      "2884\n",
      "2920\n",
      "2961\n",
      "2966\n",
      "2979\n",
      "3056\n",
      "3069\n",
      "3076\n",
      "3096\n",
      "3097\n",
      "3107\n",
      "3134\n",
      "3173\n",
      "3204\n",
      "3223\n",
      "3253\n",
      "3274\n",
      "3288\n",
      "3327\n",
      "3356\n",
      "3376\n",
      "3402\n",
      "3431\n",
      "3441\n",
      "3443\n",
      "3447\n",
      "3478\n",
      "3510\n",
      "3529\n",
      "3582\n",
      "3601\n",
      "3606\n",
      "3630\n",
      "3641\n",
      "3680\n",
      "3684\n",
      "3693\n",
      "3725\n",
      "3742\n",
      "3744\n",
      "3745\n",
      "3759\n",
      "3772\n",
      "3799\n",
      "3833\n",
      "3850\n",
      "3852\n",
      "3869\n",
      "3906\n",
      "3918\n",
      "3928\n",
      "3941\n",
      "3983\n",
      "3992\n",
      "4039\n",
      "4053\n",
      "4062\n",
      "4065\n",
      "4066\n",
      "4111\n",
      "4165\n",
      "4171\n",
      "4190\n",
      "4204\n",
      "4216\n",
      "4235\n",
      "4257\n",
      "4311\n",
      "4313\n",
      "4339\n",
      "4340\n",
      "4342\n",
      "4379\n",
      "4381\n",
      "4385\n",
      "4390\n",
      "4432\n",
      "4436\n",
      "4442\n",
      "4446\n",
      "4451\n",
      "4468\n",
      "4474\n",
      "4517\n",
      "4522\n",
      "4577\n",
      "4597\n",
      "4602\n",
      "4635\n",
      "4645\n",
      "4730\n",
      "4766\n",
      "4770\n",
      "4800\n",
      "4831\n",
      "4832\n",
      "4841\n",
      "4863\n",
      "4912\n",
      "4913\n",
      "4919\n",
      "4945\n",
      "4949\n",
      "4996\n",
      "5012\n",
      "5042\n",
      "5051\n",
      "5053\n",
      "5056\n",
      "5086\n",
      "5093\n",
      "5111\n",
      "5142\n",
      "5163\n",
      "5170\n",
      "5181\n",
      "5196\n",
      "5201\n",
      "5212\n",
      "5234\n",
      "5250\n",
      "5287\n",
      "5302\n",
      "5308\n",
      "5318\n",
      "5319\n",
      "5354\n",
      "5357\n",
      "5397\n",
      "5432\n",
      "5469\n",
      "5492\n",
      "5574\n",
      "5594\n",
      "5595\n",
      "5608\n",
      "5664\n",
      "5675\n",
      "5685\n",
      "5714\n",
      "5760\n",
      "5770\n",
      "5774\n",
      "5794\n",
      "5824\n",
      "5825\n",
      "5851\n",
      "5854\n",
      "5896\n",
      "5910\n",
      "5921\n",
      "5946\n",
      "5949\n",
      "5979\n",
      "5993\n",
      "5999\n",
      "6007\n",
      "6018\n",
      "6020\n",
      "6029\n",
      "6039\n",
      "6045\n",
      "6074\n",
      "6077\n",
      "6090\n",
      "6097\n",
      "6116\n",
      "6136\n",
      "6143\n",
      "6166\n",
      "6178\n",
      "6180\n",
      "6190\n",
      "6209\n",
      "6228\n",
      "6276\n",
      "6287\n",
      "6293\n",
      "6308\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(y_test1) - 1):\n",
    "    if y_test1[p] == 1:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predTotal = []\n",
    "# for i in range(len(y_pred1)):\n",
    "#     res = (y_pred1Prob[:, 1][i] + y_pred2Prob[:,1][i])\n",
    "#     y_predTotal.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predTotal = []\n",
    "# for i in range(len(y_pred1)):\n",
    "#     res = y_pred2Prob[:,1][i]\n",
    "#     if (y_pred1[i] != y_pred2[i]):\n",
    "#         if (y_pred2Prob[:,1][i] > y_pred1Prob[:,1][i]):\n",
    "#             res =  y_pred1Prob[:,0][i] - y_pred2Prob[:,1][i]\n",
    "#         else:\n",
    "#             res = y_pred2Prob[:,0][i] - y_pred1Prob[:,1][i]\n",
    "#     y_predTotal.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predTotal = []\n",
    "# for i in range(len(y_pred1)):\n",
    "#     if(i % 2 == 0):\n",
    "#         res = y_pred2Prob[:,1][i]\n",
    "#     else:\n",
    "#         res = y_pred1Prob[:,1][i]\n",
    "#     if (y_pred1[i] != y_pred2[i]):\n",
    "#         if (y_pred2Prob[:,1][i] > y_pred1Prob[:,1][i]):\n",
    "#             res =  y_pred1Prob[:,0][i] - y_pred2Prob[:,1][i]\n",
    "#         else:\n",
    "#             res = y_pred2Prob[:,0][i] - y_pred1Prob[:,1][i]\n",
    "#     y_predTotal.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05807730341602254\n"
     ]
    }
   ],
   "source": [
    "i = 151\n",
    "print(y_pred1Prob[:,1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2[i] + \"  \" + y_pred2Prob[:,1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2076372"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2[:,1][51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078085293457253"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test1, y_predTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510193203971102"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test1, y_pred1Prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8414716335496832"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test1, y_pred2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPrueba de StackingClassifier\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(15,15,15), max_iter = 100)\n",
    "clf2 = XGBClassifier(n_estimators = 50, subsample = 0.8, learning_rate = 0.1, colsample_bytree = 0.6)\n",
    "lr = LogisticRegression(C = 10.0)\n",
    "classifier3 = StackingClassifier(classifiers=[clf1, clf2], meta_classifier=lr)\n",
    "all_accuracies3 = cross_val_score(estimator = classifier3, X= x_train, y = y_train, cv = 5, scoring=\"roc_auc\")\n",
    "print(all_accuracies3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_accuracies3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_accuracies3.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label_array, test_size = 0.33, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridSearch RandomForest\n",
    "randomForest = RandomForestClassifier()\n",
    "grid_param = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"bootstrap\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr = GridSearchCV(estimator=randomForest, param_grid=grid_param, scoring=\"roc_auc\", cv=5, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto va a tardar\n",
    "gd_sr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muestra el mejor hiperparametro\n",
    "best_parameters = gd_sr.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muestra el mejor score\n",
    "gd_sr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridSearch XGBoost\n",
    "xgboost = XGBClassifier()\n",
    "xgb_grid_param = {\n",
    "    'max_depth': [7], #[3,4,5,6,7,8,9], # 5 is good but takes too long in kaggle env\n",
    "    'subsample': [0.6, 0.8], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 0.7], #[0.5,0.6,0.7,0.8],\n",
    "    'n_estimators': [45, 48,50, 52 ,55 ], #[1000,2000,3000]\n",
    "    'learning_rate': [0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs = GridSearchCV(estimator=xgboost, param_grid=xgb_grid_param, scoring=\"roc_auc\", cv=10, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(data_array, label_array, test_size = 0, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'n_estimators': [45, 48, 50, 52, 55], 'colsample_bytree': [0.6, 0.8, 0.7], 'max_depth': [7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gs.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 45, 'colsample_bytree': 0.8, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "#muestra el mejor hiperparametro\n",
    "#{'n_estimators': 100, 'subsample': 0.8, 'learning_rate': 0.1, 'colsample_bytree': 0.6, 'max_depth': 3}\n",
    "best_parameters = xgb_gs.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=45,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508510082409274"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra el mejor score\n",
    "xgb_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06606371, 0.06729288, 0.03013249, ..., 0.08379722, 0.14042549,\n",
       "       0.00837248], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Realizo el submit \n",
    "kaggle_predict = xgb.predict_proba(kaggle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066064</td>\n",
       "      <td>00091926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067293</td>\n",
       "      <td>00091a7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030132</td>\n",
       "      <td>000ba417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040240</td>\n",
       "      <td>000e4d9e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025915</td>\n",
       "      <td>000e619d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.035323</td>\n",
       "      <td>001001be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009550</td>\n",
       "      <td>0010e89a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009119</td>\n",
       "      <td>0016c4b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008597</td>\n",
       "      <td>001804a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010115</td>\n",
       "      <td>001a2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012249</td>\n",
       "      <td>00202cdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052218</td>\n",
       "      <td>0022965d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.054144</td>\n",
       "      <td>0027574e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.017472</td>\n",
       "      <td>00295d74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.198078</td>\n",
       "      <td>002aea56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.169273</td>\n",
       "      <td>002ed810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025907</td>\n",
       "      <td>002fb981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007931</td>\n",
       "      <td>00344873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.246234</td>\n",
       "      <td>0038a117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041149</td>\n",
       "      <td>003a05bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.105201</td>\n",
       "      <td>003d07ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013564</td>\n",
       "      <td>003e7507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.020813</td>\n",
       "      <td>00408349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.015668</td>\n",
       "      <td>0041fec6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018311</td>\n",
       "      <td>0043a48e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.248831</td>\n",
       "      <td>00546f4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.029075</td>\n",
       "      <td>00556ee5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.137924</td>\n",
       "      <td>0059a996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.027301</td>\n",
       "      <td>005af223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.013513</td>\n",
       "      <td>005e06ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19385</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>ff9e0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19386</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>ff9ebf5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19387</th>\n",
       "      <td>0.029443</td>\n",
       "      <td>ff9fc164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19388</th>\n",
       "      <td>0.218618</td>\n",
       "      <td>ffa0b2f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19389</th>\n",
       "      <td>0.016851</td>\n",
       "      <td>ffa0d7a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19390</th>\n",
       "      <td>0.018878</td>\n",
       "      <td>ffa28549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19391</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>ffacfff0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19392</th>\n",
       "      <td>0.101398</td>\n",
       "      <td>ffaee083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>0.009651</td>\n",
       "      <td>ffb4618c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19394</th>\n",
       "      <td>0.008372</td>\n",
       "      <td>ffb46215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19395</th>\n",
       "      <td>0.213601</td>\n",
       "      <td>ffb7c1a6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19396</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>ffba4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19397</th>\n",
       "      <td>0.009409</td>\n",
       "      <td>ffbb282f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>0.009100</td>\n",
       "      <td>ffbb90a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19399</th>\n",
       "      <td>0.010542</td>\n",
       "      <td>ffbfc511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19400</th>\n",
       "      <td>0.045260</td>\n",
       "      <td>ffc0f2a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19401</th>\n",
       "      <td>0.048331</td>\n",
       "      <td>ffccd5a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19402</th>\n",
       "      <td>0.037599</td>\n",
       "      <td>ffcf952b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19403</th>\n",
       "      <td>0.155707</td>\n",
       "      <td>ffd41214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19404</th>\n",
       "      <td>0.070165</td>\n",
       "      <td>ffd62616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19405</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>ffda14ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19406</th>\n",
       "      <td>0.054998</td>\n",
       "      <td>ffdafc72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19407</th>\n",
       "      <td>0.089425</td>\n",
       "      <td>ffddd0ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19408</th>\n",
       "      <td>0.050316</td>\n",
       "      <td>ffe53446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19409</th>\n",
       "      <td>0.198915</td>\n",
       "      <td>ffecea3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19410</th>\n",
       "      <td>0.099416</td>\n",
       "      <td>fff1b11a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19411</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>fff1caee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19412</th>\n",
       "      <td>0.083797</td>\n",
       "      <td>fff54d61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19413</th>\n",
       "      <td>0.140425</td>\n",
       "      <td>fff72025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19414</th>\n",
       "      <td>0.008372</td>\n",
       "      <td>fffd1246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label    person\n",
       "0      0.066064  00091926\n",
       "1      0.067293  00091a7a\n",
       "2      0.030132  000ba417\n",
       "3      0.040240  000e4d9e\n",
       "4      0.025915  000e619d\n",
       "5      0.035323  001001be\n",
       "6      0.009550  0010e89a\n",
       "7      0.009119  0016c4b5\n",
       "8      0.008597  001804a2\n",
       "9      0.010115  001a2273\n",
       "10     0.012249  00202cdb\n",
       "11     0.052218  0022965d\n",
       "12     0.054144  0027574e\n",
       "13     0.017472  00295d74\n",
       "14     0.198078  002aea56\n",
       "15     0.169273  002ed810\n",
       "16     0.025907  002fb981\n",
       "17     0.007931  00344873\n",
       "18     0.246234  0038a117\n",
       "19     0.041149  003a05bf\n",
       "20     0.105201  003d07ef\n",
       "21     0.013564  003e7507\n",
       "22     0.020813  00408349\n",
       "23     0.015668  0041fec6\n",
       "24     0.018311  0043a48e\n",
       "25     0.248831  00546f4c\n",
       "26     0.029075  00556ee5\n",
       "27     0.137924  0059a996\n",
       "28     0.027301  005af223\n",
       "29     0.013513  005e06ef\n",
       "...         ...       ...\n",
       "19385  0.150685  ff9e0500\n",
       "19386  0.010563  ff9ebf5a\n",
       "19387  0.029443  ff9fc164\n",
       "19388  0.218618  ffa0b2f3\n",
       "19389  0.016851  ffa0d7a0\n",
       "19390  0.018878  ffa28549\n",
       "19391  0.008577  ffacfff0\n",
       "19392  0.101398  ffaee083\n",
       "19393  0.009651  ffb4618c\n",
       "19394  0.008372  ffb46215\n",
       "19395  0.213601  ffb7c1a6\n",
       "19396  0.008577  ffba4aec\n",
       "19397  0.009409  ffbb282f\n",
       "19398  0.009100  ffbb90a9\n",
       "19399  0.010542  ffbfc511\n",
       "19400  0.045260  ffc0f2a0\n",
       "19401  0.048331  ffccd5a1\n",
       "19402  0.037599  ffcf952b\n",
       "19403  0.155707  ffd41214\n",
       "19404  0.070165  ffd62616\n",
       "19405  0.008577  ffda14ca\n",
       "19406  0.054998  ffdafc72\n",
       "19407  0.089425  ffddd0ec\n",
       "19408  0.050316  ffe53446\n",
       "19409  0.198915  ffecea3d\n",
       "19410  0.099416  fff1b11a\n",
       "19411  0.008577  fff1caee\n",
       "19412  0.083797  fff54d61\n",
       "19413  0.140425  fff72025\n",
       "19414  0.008372  fffd1246\n",
       "\n",
       "[19415 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_submit = {'person': kaggle[\"person\"], 'label': kaggle_predict[:,1]}\n",
    "kaggle_submitDF = pd.DataFrame(data=kaggle_submit)\n",
    "kaggle_submitDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submitDF.to_csv('setSubmit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
