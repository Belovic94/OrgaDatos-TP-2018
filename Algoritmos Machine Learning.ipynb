{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticReg(x_train, x_test, y_train, y_test):\n",
    "    logReg = LogisticRegression(solver='sag', random_state=1)\n",
    "    logReg.fit(x_train, y_train)\n",
    "    y_pred = logReg.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, x_train, x_test, y_train, y_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(max_depth, max_features, x_train, x_test, y_train, y_test):\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(max_depth, n_estimators, x_train, x_test, y_train, y_test):\n",
    "    xgb = XGBClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(nEstimators, learningRate, x_train, x_test, y_train, y_test):\n",
    "    ada = AdaBoostClassifier(n_estimators=nEstimators, learning_rate=learningRate, random_state=0)\n",
    "    ada.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)\n",
    "#n_estimators is the number of models to iteratively train.\n",
    "#learning_rate is the contribution of each model to the weights and defaults to 1. \n",
    "#Reducing the learning rate will mean the weights will be increased or decreased to a small degree, \n",
    "#forcing the model train slower (but sometimes resulting in better performance scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(baseEstimator, nEstimators, learningRate, max_feature, bootstrap, bootstrap_feature, x_train, x_test, y_train, y_test):\n",
    "    bag = BaggingClassifier(base_estimator=base_estimator, n_estimators=nEstimators, max_features=max_feature, bootstrap=bootstrap, bootstrap_features=bootstrap_feature, random_state=seed)\n",
    "    bag.fit(x_train, y_train)\n",
    "    y_pred = bag.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientboost(nEstimators, learningRate, maxDepth, x_train, x_test, y_train, y_test):\n",
    "    grad = GradientBoostingClassifier(n_estimators=nEstimators, learning_rate=learningRate, max_depth=maxDepth)\n",
    "    grad.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#TAMBIEN PUEDEN USAR PARA VER EL ACCURACY\n",
    "#ACCURACY = accuracy_score(y_test, y_pred)\n",
    "#The maximum depth limits the number of nodes in the tree. \n",
    "#Tune this parameter for best performance; the best value depends on the interaction of the input variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
